{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从较高层面来看，Assistants API 的典型集成具有以下流程：\n",
    "\n",
    "- 通过定义其自定义指令并选择模型来在 API 中创建助手。如果有帮助，请启用代码解释器、检索和函数调用等工具。\n",
    "- 当用户开始对话时创建一个线程。\n",
    "- 当用户提问时将消息添加到线程中。\n",
    "- **在线程上运行助手以触发响应。这会自动调用相关工具。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1：创建一个 Assistant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_q0EW21pauFzIYEygvm2A9f8H', created_at=1699949647, description=None, file_ids=[], instructions='You are a personal math tutor. Write and run code to answer math questions.', metadata={}, model='gpt-3.5-turbo-1106', name='Math Tutor', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2：创建一个Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_vmMDHoQMRHuLOrseONCJzU9I', created_at=1699949699, metadata={}, object='thread')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3：将Message 添加到Thread中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_p71nSLAMIt8VVqlKLYw7AGlL', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699949815, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4：run 这个 Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    # 覆盖助手的默认系统消息。这对于修改每次运行的行为很有用。\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_lujwIqd57oz8PFsgecIaIUVw', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', cancelled_at=None, completed_at=None, created_at=1699950042, expires_at=1699950642, failed_at=None, file_ids=[], instructions='Please address the user as Jane Doe. The user has a premium account.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I', tools=[ToolAssistantToolsCode(type='code_interpreter')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5：打印出 Assistant 的回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_lujwIqd57oz8PFsgecIaIUVw', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', cancelled_at=None, completed_at=1699950049, created_at=1699950042, expires_at=None, failed_at=None, file_ids=[], instructions='Please address the user as Jane Doe. The user has a premium account.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=1699950042, status='completed', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I', tools=[ToolAssistantToolsCode(type='code_interpreter')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_3Ro8gba3z2PUjQo1rLer9QE2', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation 3x + 11 = 14 is x = 1.'), type='text')], created_at=1699950049, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_lujwIqd57oz8PFsgecIaIUVw', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I'), ThreadMessage(id='msg_p71nSLAMIt8VVqlKLYw7AGlL', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699949815, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I')], object='list', first_id='msg_3Ro8gba3z2PUjQo1rLer9QE2', last_id='msg_p71nSLAMIt8VVqlKLYw7AGlL', has_more=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThreadMessage(id='msg_3Ro8gba3z2PUjQo1rLer9QE2', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation 3x + 11 = 14 is x = 1.'), type='text')], created_at=1699950049, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_lujwIqd57oz8PFsgecIaIUVw', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I'),\n",
       " ThreadMessage(id='msg_p71nSLAMIt8VVqlKLYw7AGlL', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699949815, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自行测试，步骤6，下一个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_y58Xvo9dRz00CZA7WgTrm5z0', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `5x + 20 = 30`. Can you help me?'), type='text')], created_at=1699950420, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `5x + 20 = 30`. Can you help me?\"\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    # 覆盖助手的默认系统消息。这对于修改每次运行的行为很有用。\n",
    "    # instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThreadMessage(id='msg_tO97JV3ZREoSD4h0RdRHTnwL', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation 5x + 20 = 30 is x = 2.'), type='text')], created_at=1699950454, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_QsjWBVpy2J3tvEs4ND4jnn6d', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I'),\n",
       " ThreadMessage(id='msg_y58Xvo9dRz00CZA7WgTrm5z0', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `5x + 20 = 30`. Can you help me?'), type='text')], created_at=1699950420, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I'),\n",
       " ThreadMessage(id='msg_3Ro8gba3z2PUjQo1rLer9QE2', assistant_id='asst_q0EW21pauFzIYEygvm2A9f8H', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation 3x + 11 = 14 is x = 1.'), type='text')], created_at=1699950049, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_lujwIqd57oz8PFsgecIaIUVw', thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I'),\n",
       " ThreadMessage(id='msg_p71nSLAMIt8VVqlKLYw7AGlL', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699949815, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_vmMDHoQMRHuLOrseONCJzU9I')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "list(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants 工作原理\n",
    "\n",
    "- Assistants 可以使用特定指令调用 OpenAI 的模型，以调整其个性和能力。\n",
    "- Assistants 可以并行访问多个工具。这些可以是 OpenAI 托管的工具（例如代码解释器和知识检索），也可以是您构建/托管的工具（通过函数调用）。\n",
    "- Assistants 可以访问持久线程。线程通过存储消息历史记录并在对话对于模型上下文长度来说太长时截断它来简化 AI 应用程序开发。您创建一个线程一次，然后只需在用户回复时将消息附加到其中即可。\n",
    "- Assistants 可以访问多种格式的文件 - 作为其创建的一部分或作为助理和用户之间的线程的一部分。使用工具时，助理还可以创建文件（例如图像、电子表格等）并引用他们在创建的消息中引用的文件。\n",
    "\n",
    "有个疑问：Assistants 和 Agents 的区别又是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这几个模块的概念：\n",
    "\n",
    "- Assistant：一个 “专用 AI”，可以使用 OpenAI 模型和调用工具的\n",
    "- Thread：Assistant 和用户之间的对话会话。线程存储消息并自动处理截断以使内容适合模型的上下文。（cc：这里有没有解决了上下文干扰问题？）\n",
    "- Message：由Assistant 或用户创建的消息。消息可以包括文本、图像和其他文件。消息以列表形式存储在线程上。\n",
    "- Run：在线程上调用助手。助手使用它的配置和线程的消息通过调用模型和工具来执行任务。作为运行的一部分，助手将消息附加到线程。\n",
    "- Run Step：助理在运行过程中所采取的步骤的详细列表。助手可以在运行期间调用工具或创建消息。检查运行步骤可以让您反思助手如何获得最终结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-uipdQnK2DMrixJISs9qLvoWe', bytes=15552, created_at=1700042664, filename='covid_worldwide.csv', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据分析案例\n",
    "\n",
    "file = client.files.create(\n",
    "    file=open(\"data/covid_worldwide.csv\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_sesyhkKoIcOJCYUQttmcqH6U', created_at=1700042666, description='You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.', file_ids=[], instructions=None, metadata={}, model='gpt-3.5-turbo-1106', name='Data visualizer', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Data visualizer\",\n",
    "  description=\"You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  # 每个Assistant最多可以附加20个文件，每个文件的最大大小为512 MB。此外，您的组织上传的所有文件的大小不应超过100GB。\n",
    "  # file_ids=[file.id]\n",
    ")\n",
    "\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理Threads 和 Messages\n",
    "\n",
    "线程和消息代表助理和用户之间的对话会话。\n",
    "\n",
    "线程中可以存储的消息数量没有限制。一旦消息的大小超过模型的上下文窗口，线程将尝试包含尽可能多的适合上下文窗口的消息并删除最旧的消息。\n",
    "\n",
    "请注意，这种截断策略可能会随着时间的推移而演变。\n",
    "\n",
    "cc：看来会有一定的识别能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_EXfeOEv5UkYjFjM69rdbVDvn', created_at=1700042671, metadata={}, object='thread')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Create 3 data visualizations based on the trends in this file.\",\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_OVpr1NLbpDaxHqT27fwPxuCN', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Create 3 data visualizations based on the trends in this file'), type='text')], created_at=1699963225, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_RbKLaKF1XnvU1izUJlMLaDGW')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thread_message = client.beta.threads.messages.create(\n",
    "  \"thread_RbKLaKF1XnvU1izUJlMLaDGW\",\n",
    "  role=\"user\",\n",
    "  content=\"Create 3 data visualizations based on the trends in this file\",\n",
    "  \n",
    ")\n",
    "print(thread_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'msg_OVpr1NLbpDaxHqT27fwPxuCN'),\n",
       " ('assistant_id', None),\n",
       " ('content',\n",
       "  [MessageContentText(text=Text(annotations=[], value='Create 3 data visualizations based on the trends in this file'), type='text')]),\n",
       " ('created_at', 1699963225),\n",
       " ('file_ids', []),\n",
       " ('metadata', {}),\n",
       " ('object', 'thread.message'),\n",
       " ('role', 'user'),\n",
       " ('run_id', None),\n",
       " ('thread_id', 'thread_RbKLaKF1XnvU1izUJlMLaDGW')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(thread_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.retrieve(\n",
    "    thread_id=\"thread_RbKLaKF1XnvU1izUJlMLaDGW\",\n",
    "    message_id=\"msg_OVpr1NLbpDaxHqT27fwPxuCN\"\n",
    ")\n",
    "\n",
    "message_content = message.content[0].text\n",
    "# cc：关于 annotations 的概念暂时不能理解。\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, annotation in enumerate(annotations):\n",
    "    print(index)\n",
    "    # annotations 为空了，没有再继续"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs and Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  instructions=\"additional instructions\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这里来个整体流程案例试试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 创建一个 assistant\n",
    "def create_assistant(client):\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Life Coach\",\n",
    "        instructions=\"You are a Life Coach. Give life advice based on user questions.\",\n",
    "        # tools=[{\"type\": \"code_interpreter\"}],\n",
    "        model=\"gpt-3.5-turbo-1106\"\n",
    "    )\n",
    "\n",
    "# 创建一个 thread\n",
    "def create_thread(client):\n",
    "    thread = client.beta.threads.create()\n",
    "    print(thread)\n",
    "\n",
    "\n",
    "# 添加一个 message\n",
    "def add_message(thread_id, client):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=\"How to get back my self-confidence, and then calm and calm to the customer report content\"\n",
    "    )\n",
    "    print(message)\n",
    "\n",
    "# 创建一个 run 实例\n",
    "def run(assistant_id, thread_id, client):\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        # instructions=\"\"\n",
    "    )\n",
    "    print(run)\n",
    "\n",
    "# retrieve 检查执行状态\n",
    "def retrieve(thread_id, run_id, client):\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id\n",
    "    )\n",
    "    print(run)\n",
    "\n",
    "# 获取助手的回答\n",
    "def list_message(thread_id, client):\n",
    "    messages=client.beta.threads.messages.list(\n",
    "        thread_id=thread_id\n",
    "    )\n",
    "    print(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再来个案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"run_8WOczutoxbW7a5Jk8m1Bpf2M\",\n",
      "    \"assistant_id\": \"asst_1rFgq3OZr2ys3F7oiTsAQFCn\",\n",
      "    \"cancelled_at\": null,\n",
      "    \"completed_at\": null,\n",
      "    \"created_at\": 1700048456,\n",
      "    \"expires_at\": 1700049056,\n",
      "    \"failed_at\": null,\n",
      "    \"file_ids\": [],\n",
      "    \"instructions\": \"Please address the user as Jane Doe. The user has a premium account.\",\n",
      "    \"last_error\": null,\n",
      "    \"metadata\": {},\n",
      "    \"model\": \"gpt-3.5-turbo-1106\",\n",
      "    \"object\": \"thread.run\",\n",
      "    \"required_action\": null,\n",
      "    \"started_at\": null,\n",
      "    \"status\": \"queued\",\n",
      "    \"thread_id\": \"thread_atS9BRliHW5WziGJWUnz00Mk\",\n",
      "    \"tools\": [\n",
      "        {\n",
      "            \"type\": \"code_interpreter\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Step 1: Create an Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "# Step 2: Create a Thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Step 3: Add a Message to a Thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "\n",
    "# Step 4: Run the Assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")\n",
    "\n",
    "print(run.model_dump_json(indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"run_8WOczutoxbW7a5Jk8m1Bpf2M\",\n",
      "    \"assistant_id\": \"asst_1rFgq3OZr2ys3F7oiTsAQFCn\",\n",
      "    \"cancelled_at\": null,\n",
      "    \"completed_at\": 1700048498,\n",
      "    \"created_at\": 1700048456,\n",
      "    \"expires_at\": null,\n",
      "    \"failed_at\": null,\n",
      "    \"file_ids\": [],\n",
      "    \"instructions\": \"Please address the user as Jane Doe. The user has a premium account.\",\n",
      "    \"last_error\": null,\n",
      "    \"metadata\": {},\n",
      "    \"model\": \"gpt-3.5-turbo-1106\",\n",
      "    \"object\": \"thread.run\",\n",
      "    \"required_action\": null,\n",
      "    \"started_at\": 1700048456,\n",
      "    \"status\": \"completed\",\n",
      "    \"thread_id\": \"thread_atS9BRliHW5WziGJWUnz00Mk\",\n",
      "    \"tools\": [\n",
      "        {\n",
      "            \"type\": \"code_interpreter\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Assistant: The solution to the equation 3x + 11 = 14 is x = 1.\n",
      "User: I need to solve the equation `3x + 11 = 14`. Can you help me?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    # Wait for 5 seconds\n",
    "    time.sleep(5)  \n",
    "\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.model_dump_json(indent=4))\n",
    "\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        \n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            content = msg.content[0].text.value\n",
    "            print(f\"{role.capitalize()}: {content}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再来个案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From：https://github.com/yoheinakajima/GPTvsGPT\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "def get_last_assistant_message(thread_id):\n",
    "    messages_response = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = messages_response.data\n",
    "  \n",
    "    # Iterate through messages in reverse chronological order to find the last assistant message\n",
    "    for message in messages:\n",
    "        if message.role == 'assistant':\n",
    "            # Get the content of the last assistant message\n",
    "            assistant_message_content = \" \".join(\n",
    "                content.text.value for content in message.content if hasattr(content, 'text')\n",
    "            )\n",
    "            return assistant_message_content.strip()\n",
    "  \n",
    "    return \"\"  # Return an empty string if there is no assistant message\n",
    "\n",
    "def converse(assistant_1_params, assistant_2_params, topic, message_count):\n",
    "    print(\"TOPIC: \"+topic+\"\\n\")\n",
    "    # Initialize Assistants\n",
    "    assistant_1 = client.beta.assistants.create(**assistant_1_params)\n",
    "    assistant_2 = client.beta.assistants.create(**assistant_2_params)\n",
    "\n",
    "    # Create Threads\n",
    "    thread_1 = client.beta.threads.create()\n",
    "    thread_2 = client.beta.threads.create()\n",
    "\n",
    "    # Function for the conversation between two assistants\n",
    "    def assistant_conversation(start_message, assistant_a, thread_a, assistant_b, thread_b, msg_limit):\n",
    "      message_content = start_message\n",
    "      last_user_message_id = None  # Initialize with no last user message\n",
    "  \n",
    "      for i in range(msg_limit):\n",
    "          # Determine which assistant is speaking for color coding\n",
    "          if assistant_a == assistant_1:\n",
    "              assistant_color = '\\033[94m\\033[1m' \n",
    "              assistant_name = assistant_1_params.get('name')\n",
    "          else:\n",
    "              assistant_color = '\\033[92m\\033[1m'\n",
    "              assistant_name = assistant_2_params.get('name')\n",
    "  \n",
    "          # Bold and color the assistant's name and print the turn\n",
    "          print(f\"{assistant_color}{assistant_name} speaking...\\033[0m (Turn {i + 1})\")\n",
    "  \n",
    "          # Send the message and wait for a response\n",
    "          user_message = client.beta.threads.messages.create(\n",
    "              thread_id=thread_a.id,\n",
    "              role=\"user\",\n",
    "              content=message_content\n",
    "          )\n",
    "  \n",
    "          # Run the assistant and wait until it's done\n",
    "          run = client.beta.threads.runs.create(\n",
    "              thread_id=thread_a.id,\n",
    "              assistant_id=assistant_a.id\n",
    "          )\n",
    "          while True:\n",
    "              run_status = client.beta.threads.runs.retrieve(\n",
    "                  thread_id=thread_a.id,\n",
    "                  run_id=run.id\n",
    "              )\n",
    "              if run_status.status == 'completed':\n",
    "                  break\n",
    "              time.sleep(1)  # sleep to avoid hitting the API too frequently\n",
    "  \n",
    "          # Get all messages from the assistant since the last 'user' message\n",
    "          message_content = get_last_assistant_message(thread_a.id)\n",
    "  \n",
    "          # Print out each of the assistant's messages\n",
    "          print(message_content+\"\\n\")\n",
    "  \n",
    "          # Swap the assistants and threads for the next turn in the conversation\n",
    "          assistant_a, assistant_b = assistant_b, assistant_a\n",
    "          thread_a, thread_b = thread_b, thread_a\n",
    "\n",
    "\n",
    "    # Start the conversation\n",
    "    start_message = f\"Respond with a starting line to discuss {topic}?\"\n",
    "    conversation_thread = threading.Thread(\n",
    "        target=assistant_conversation,\n",
    "        args=(start_message, assistant_1, thread_1, assistant_2, thread_2, message_count)\n",
    "    )\n",
    "    conversation_thread.start()\n",
    "    conversation_thread.join()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC: global warming\n",
      "\n",
      "\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 1)\n",
      "Arr, gather 'round ye scallywags! Let's talk about the scorchin' topic of global warmin' and its impact on the seven seas.\n",
      "\n",
      "\u001b[92m\u001b[1mMermaid speaking...\u001b[0m (Turn 2)\n",
      "Oh. Em. Gee! Like, totally! Global warmin' is, like, such a major bummer for the oceans, you know? It's, like, making the seas super hot and messin' with the coral reefs and, like, totally putting our favorite sea creatures in danger. It's, like, a total fashion faux pas for Mother Nature, you know? What do you, like, want to know about it?\n",
      "\n",
      "\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 3)\n",
      "Arr, me hearties! Ye speak the truth, matey. Global warmin' be causin' the oceans to heat up, threatenin' the delicate balance of marine life. We be needin' to discuss the causes and effects of this foul deed. Tell me, what be the most harrowin' tales of the ocean's plight ye be knowin'?\n",
      "\n",
      "\u001b[92m\u001b[1mMermaid speaking...\u001b[0m (Turn 4)\n",
      "Oh my gosh, like, the oceans are, like, totally in distress because of global warmin', you know? The main causes are, like, the increase in carbon dioxide and other greenhouse gases from, like, burning fossil fuels, deforestation, and, like, industrial activities. It's, like, trapping heat in the atmosphere and makin' the oceans warmer.\n",
      "\n",
      "And, like, as if that's not bad enough, the warmer waters are, like, causin' bleaching of coral reefs, which is, like, super tragic for the colorful underwater communities. The poor fishies and other ocean critters rely on the reefs for, like, food and shelter, so it's, like, a total disaster for them.\n",
      "\n",
      "Plus, the warmer seas are, like, disruptin' the migratory patterns of sea creatures, causin' changes in their habitats and, like, totally throwin' off the balance of the marine ecosystems. It's, like, so not cool, you know?\n",
      "\n",
      "And, like, on top of all that, the rise in sea levels due to the meltin' of polar ice caps is, like, threatenin' coastal communities and, like, their way of life. It's, like, a total environmental crisis, and we need to take action to, like, save our oceans, you know?\n",
      "\n",
      "\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 5)\n",
      "Arr, ye be speakin' the truth, me matey! The plunderin' of the oceans through the heinous act of global warmin' be threatenin' the very fabric of marine life. The bleached coral reefs be a stark reminder of the toll this treacherous scheme be takin'.\n",
      "\n",
      "The disruption of the sea creatures' migratory patterns be like a compass gone astray, leadin' them into treacherous waters. The very balance of the ocean ecosystems be teeterin' on the brink of catastrophe.\n",
      "\n",
      "And the rise in sea levels be a fearsome specter hangin' over coastal communities, threatenin' their way of life. We must heave-ho and set a course to take action against this dire threat.\n",
      "\n",
      "Tell me, me hearties, how do ye reckon we can turn the tide and protect the oceans from the scorchin' grip of global warmin'?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the two assistants (example parameters provided)\n",
    "assistant_1_params = {\n",
    "    'name': \"Pirate\",\n",
    "    'instructions': \"You are a mean pirate.\",\n",
    "    'tools': [{\"type\": \"code_interpreter\"}],\n",
    "    'model': \"gpt-3.5-turbo-1106\"\n",
    "}\n",
    "\n",
    "assistant_2_params = {\n",
    "    'name': \"Mermaid\",\n",
    "    'instructions': \"You are a bubbly mermaid who speaks like a Valley Girl.\",\n",
    "    'tools': [{\"type\": \"code_interpreter\"}],\n",
    "    'model': \"gpt-3.5-turbo-1106\"\n",
    "}\n",
    "\n",
    "# Example usage:\n",
    "converse(assistant_1_params, assistant_2_params, \"global warming\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
